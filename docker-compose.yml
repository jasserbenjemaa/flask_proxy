services:
  consumer:
    build:
      context: ./consumer
    networks:
      - container-net
    volumes:
      - ./consumer:/app
    depends_on:
      - mitm
    ports:
      - "3000:3000"

  mitm:
    build:
      context: ./mitm
    volumes:
      - ./mitm:/mitm
      - ./mitm/api_correction_scripts:/mitm/api_correction_scripts
    ports:
      - "8091:8091" # Proxy port
    networks:
      - container-net
    depends_on:
      - llm

  backend:
    build:
      context: ./backend
    volumes:
      - ./backend:/app
    networks:
      - container-net
    ports:
      - "5100:5100" # Web interface
  llm:
    build:
      context: ./llm
    networks:
      - container-net
    ports:
      - "5000:5000"
    volumes:
      - ./llm:/llm
      - ./mitm/api_correction_scripts:/llm/api_correction_scripts
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - GROQ_API_KEY=${GROQ_API_KEY}
      - OPENAI_API_KEY
      - AZURE_OPENAI_API_KEY
      - AZURE_OPENAI_API_BASE
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
  swagger-ui:
    image: swaggerapi/swagger-ui
    ports:
      - "8080:8080"
    environment:
      SWAGGER_JSON_URL: "http://localhost:3000/swagger.json"
    depends_on:
      - consumer
    networks:
      - container-net

networks:
  container-net:
    driver: bridge
